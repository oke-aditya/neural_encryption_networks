{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encrpyter_Decrypter_Net_V1_2_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfntcH0W00ee"
      },
      "source": [
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ21dR9P8gVv"
      },
      "source": [
        "from keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlM85BbVUrv7"
      },
      "source": [
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_XK9X5oPsL7"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La699KWSPsME"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klol-OGDPsMK"
      },
      "source": [
        "def create_labels(paragraph, hashmap):\n",
        "    # paragraph = paragraph.lower()\n",
        "    output = []\n",
        "    for i in paragraph:\n",
        "        output.append(list(map(int,str(hashmap[i]))))\n",
        "    \n",
        "    return np.array(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DyLy5GF7lnD"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrY57mTsbIaw"
      },
      "source": [
        "def create_labels(paragraph, hashmap):\n",
        "    # paragraph = paragraph.lower()\n",
        "    output = []\n",
        "    for i in paragraph:\n",
        "        output.append(list(map(int,str(hashmap[i]))))\n",
        "    \n",
        "    return np.array(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itrWMHP4Um05"
      },
      "source": [
        "hashmap = {\"'\": 10111011000011101101110111001001101100100100111011011110, 'G': 10001011010100101010111001101011000110011000000101011000, '/': 10111111101101010001111100100111101110010100010101111100, 'o': 11100001001101001010110011000001011101000110110101111110, 'I': 10101000100010011101111111100110110111000001000110000110, 'n': 11110001010010111001110100111011100011110101110110000010, 'X': 11010100010001101011001011101010110100000101010010101011, 'i': 10010110111011100111110001101111011111101000011111111010, ']': 10110010010011111000010101100110000110011011111000100001, 'b': 10100010010010100010010111001101000011000101000100101010, '6': 11001011100100011010001011100001011111100011010011000001, 'O': 10010101010001110010110000011101000010010100101010010010, '9': 11100110000001101111110000101100000001111011010001110110, '4': 11011111010001110011010100100010100100010010111010111101, 'm': 10110001101011110001111100111111001001100011110101110101, '*': 11010011011100011000111011101100111011110010011110001011, 'f': 10100110100010100100111000111000000000110101001110110111, 'S': 11100001001001010011011101010010011000010001011100100100, ',': 11100011001100101111001111101010101001000101101001000111, '`': 10101010010010001000011011001001010001111000111101110010, 'x': 10001101011110011100101100000000111011001111011010000110, 'e': 11011010100111111110100110011010110101110100101110110111, 'K': 10101000100100001100011011101010010010001111001011111010, 'Z': 10101100010101001010010011100000001100111101011101011001, 'W': 11010011100100101100010001100011111111000111000100010110, 'T': 11110011000111100100011100001000100110011100111001111110, ';': 11001000000011011011011101101011010000001100100001001100, '-': 11100110000011111000100011010000010110111011101001101110, 't': 11000010000001101101000100001010101000010111110110100000, 'R': 10001001011111101011101110001010011010001011000011111000, '^': 11010011100000100001100011111010010110110100001010100001, 'F': 11111010100101011010100101111100110100001010110101111100, 'D': 11100011101100000011010100101010110111101101010000011110, '@': 11010001110110101011000010100000000101010101101110101110, '&': 10110100001111110010001101001011001100011000011100100000, '%': 10011100101111110110111011010101110110100000010111010011, 'k': 11011110110110010100101100000000111011010000001110011100, 'd': 11101110101111011011111111000000101010100001010110111111, 'L': 11100000011100100100110100110110111001000011100111101110, '!': 10101110011000001001010111000011111101111110010001010010, '.': 10011001001101110011001111111110100000001101100110001001, '#': 10110101011011111110111100101101011111010001010011111010,\n",
        "           '3': 10001011000000011101110000001100110000010010101111001010, ')': 11101111010001100111011010101011010100101010110100111000, '$': 10110111110011001111110000001111000011111111111100110110, ' ': 11000000101101010001111000000011010010111101111011011100, '=': 11100000100010111111001001111111111011001101011111100111, '(': 10000011011001000101100010011100111100101111111010100111, 'H': 10111110101100001011101010010111110011111011011001111111, 'r': 10011000010011100010101000010000110000111101011111100011, 'N': 11110001001001111001000110110101011100000101000011000000, 'M': 10001101111001011001011100010001010011110010011000011010, 'u': 11101111110110000101010110101111101010001110100000111011, 'V': 10111101111010100011000100101011011100010101011100001100, 'p': 11101001100000011010111110110110110010100110010001010010, 'a': 10001011100100110000011110001101101101001010010100000011, '?': 11100111010110110000011000011100000101010000101011110100, 'v': 11111101000010100110001001101000010001000010111001011100, '[': 11001100000000100001111001011101001000011100011111010111, ':': 11100011110100010111001111011100110110011110111110010101, '_': 10010000010010101111110101100000110011111001011000110011, 'j': 11111000100110000010110101011111000101100100011001101110, 'l': 10111100001111101010011110101011000001000110000011111100, '1': 11001000100111111011011011100111000110101100101110010000, '+': 10000100111011111001010010101111010011100010110000100110,\n",
        "           '2': 10011010010011110000011110000011110110001000000001111001, 'w': 11111111101001111101001010001110101010100111001111100010, 'q': 11000010100010110000101000100100010011111100110011001111, 'U': 10111101100010001000100010011011000000001001111001100101, 'c': 11000001100110111101010001011001001011100010001100011101, '5': 10011111001110011101111101011011000010001001101100001101, '\\\\': 10111100010111011100001001000111000111110100101000111101, 'h': 10010101011110111101011100010100110010011111110101000110, '<': 10100010100000011001000100110011011001011111111000000111, 'C': 11000110011000100100101100001101101010011100011100100101, 'J': 11110010011111001001111010100000100010111101000110011000, 's': 10010000001010111010110101010001011100000101010011101110, 'P': 10011101111000111100100110000001111010111100000001011001, '8': 10101111101100100110111000001000111101111010101000001101, 'B': 11110011010011100011010111001011010000010111011110101010, 'g': 11101100000000110001100101101110100101110100110001011100, 'Y': 10111011111101101111000111100111011011111110001100111110, '\"': 10001000101011010010010011011110010001011011010011101110, 'E': 10001000110111111011001010111111010000011000001000001101, 'z': 11111011010100000010010010010011110010001000011111101000, 'Q': 11100110110010010010010011111010011110101111111010001110, '>': 11001011100110111000000110101000000001010000110101100010, 'y': 10000110110110110100100111000111000011101011110111010000, '0': 11001010101000011011100110001010001110000100110101001110, '7': 11111110110010111001010000001110101101010101000010111111, 'A': 10110011101111111010100000001000010000011000110101111110}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXmRpG7-XzXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12281de-2b30-4e6f-b4d8-b234e6295ce8"
      },
      "source": [
        "print(len(hashmap))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k05ppUleX1Ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e90eac7-d259-45b2-bdb5-91bdc418e1e5"
      },
      "source": [
        "l = []\n",
        "for i in hashmap.keys():\n",
        "    l.append(i)\n",
        "\n",
        "print(sorted(l))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rW5-ALCYARj"
      },
      "source": [
        "def create_input_array(word):\n",
        "    enc_l = []\n",
        "    for i in word:\n",
        "        arr = np.zeros(91)\n",
        "        enc = ord(i) - 32\n",
        "#         print(enc)\n",
        "        arr[enc] += 1\n",
        "        enc_l.append(arr)\n",
        "    return(np.array(enc_l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIzJTfqpaize"
      },
      "source": [
        "X_train_string = '''b'Kp]I! S t\"ayQ<w )8tfwP 178 ]R?Dop gBv )1 mJE#@N79-= f+ b*=z @<z`-e>mg$ `5Uv8)j*= fyVUjtBI1^ /+ktvxSF[ 6n*VJj9Pu 5[3>0 L9# *6;X k/y[ \\'OSQ2,RCF 5.razd4T `HW;#=84rs _ fX[;+ z?!m0V P1inV7C.kF \\'k5,bO ziyek H3.TAG\\\\1 w?cf652J PYg-x1 .oqv bm ] $VCIi^Hnu WDHb az6d<Q7L% vi)6]J8 7X Leb 2N4 3EUe: wUsr $;v #gp i1 Sd b7e@C:.I^< 64t$UdmiC b1 y3u=2*$h 6K3ex\" 2y%?c z *(SK[C -96\\\\ Vx%zq2 Z N!;BKSh ]d[t;4< u/aF7;R* B6@iq\\'d& PT \\' eJw6vz@4g/ NH@) 9L6o%b_v#! 4w6.f f]rp%2\"b\\'q 1 IAB[Z\\\\vl=0 VA v*^L<f r=vm\"gS9 JXj.W$ B<bw5L7zk a`*9;s[# /v-+\"Q n.GPh ,KmgE;Mfk& bV9?Zo XArG_  Go*nD,U .@\"!2xhaz` Eyx 4W;r>N17\"l .!m/YDU9 @x>\\\\th8   r 49 ]cN_`gWM .^+lDGc Xu^-+ Py8?J:xv\" (2/ aX!t<>  $aR we3)bHT u2#>B@o)d SsAbV bOL?] b1G%;+L4C2 kY(*zJ TPzfk 8[Imd` CK [`a;vtK 1.X=!4<ut ` Ym%xF-J ,Z5zEa\\\\uj Swn= W=8J.aSys  6# w.\"o/x2tM y8 )Y-$ r.V$gTh1= Tu @T LPX . Bl2UQM5 rFyk\"_Lv o0MV ,I.m\\\\)?n 1o4s2pqQ<n mU5iB`FG +$x6LyIo0  hEWB] V$F8+iR q:Nz LA\"sm pmvA y)be>=8/q \" \"e,RiT!a `*:GiUu,a vwd$\\\\J &8\\\\ ad -Ll%)0U  zSWQ?s [-D a.o( D`/LVy ,Nc\\\\R_hXU Ap)_5Nur HF5?TqK ,t8? QD [v&0/g] c2xW;3# Y O^/9#xupg Y <ndO m G)Y`W=H\\' ]@w T3=l28\\'K< qr+ mt/Pw5nE; ]P3I5+Q*. 4 r$R\\\\8 Gh -W>V$Q^ #94gwd c-C\\'T4D]i^ $!# +M=L\\'< J8]2 kCQZid&<: q#1d.L4/ B[A qKNuS<Fo 7 &a$ rxL.6 ^>m\\\\icO ljuZ?63r4H e=JREx+ R*#WgF2KBu , DQESp \"Lu ^buw $V>P7 +9=8S 3?I,jw U- E>[$ uUQcG 0d ;]SC eb*_\"+ jM\\'VYFk &T ulRH,ti D@Z<H 6:m;z hBc_gk q <0*W47\\\\v os Mq2\\'ixuj QX;u#R/ j I4\"D 4Yb N- *X.! X&J?B\"O S0_Yxi1bB uL9x7q @ 0K^N d,U;vRm @\\' GXRq=\\\\]x9 nA&JkvH( Rw, `\":3 sg pD,Mb # i?r=:% N$\"e XVKUs  8mXW)+1x =?>.B0 #!rW(y@c/ )1IX,\\' HLhn82 $Q i,$Ld. \\'Dj3 za If&@g+MS_e pM\\'C; -2w#e6n0!I Yu@<M n,U-KybB TmQW 206N]t &H>*/TCiy 6z`20 PA?9  [Ge)2 !CM_e :KPlH5e\\' .]F=z ZC (dVD#6e pw?a=:P EydjZYGRpV nz_Rs !hN.9C\"x JbRm $6<I n^N/u\\\\,[-x %+ > /Pc\\'6 t \\\\#:7jkfh 1=^b:`\" a; q ?= MI_oY[7xf Lf<qUC6pb? >/U\\\\VbE87 #> \\\\)Co xmGB3zP4Fj \" _w-*jc`K `_5wDMP^! /ZN0 #1* ,HX y*Y&R\" dPfyk\\\\`JmE < D9cC=L7;([ tlsiuK /1 Yb7g2dHx3  4*Th26%rA Xl+vqKhw zF-<Km(B :z(%gfoqt mN\"^I08Qo > w.o] N a EyC T6<O= %< v&k_ h_C,7o AKV,C8]JBr OB&S iSc\\' 5&J>CX #f `3#mv\\\\ ZfMNxO V[G&\\' g4lU9$ W? i>R efZ\\\\I ?  &fW-253Kp i t3.,YE EV8# T_l QfA , XBlCu 5,\":A[O7Y Z]a,.Do &q,cn-C> WQb<\\\\` >pR6<5XWvb >o2d[3Fs W`\" ;T\\'Bz\",jE S ^t, (6Iy2)nZ j;LKY^S PLXNC =QUWq 8-Ze^l y\\\\cYS^%<n 1:qHwyjE r*V/1 MSjN AhuQN2\"Z_w U zvGf64h<yd nis1o7NaV T]C(Aqm? JSyT+xznO  NP]^#2qIiU iU^h*L PBWvyue1^ Yz2 `2^ 7\\'xn> ?Wv[rH,Fa H.d:-G ([ JxmjAwe.Q ]8Nx0ZM3@< xvP5eou xhIM cqp/(C\\'Jw) \\'H= oAPm:\"v@ $!Gx=-\\\\P aKWo .f4Wpw\\\\)Tx kv> wWt Xnq;!^0 N . FCK h5c3s=EITX ?v o1 Z9Ev[8=yI CHAMQdSjh WiX9q] m&L<s ku]5c<&, qhSI7M?*u PdSAesLM6 .u1J\\\\iA! 1 Z5M:fp %[9GH:RC RuxY `G=:,7> [;2NB c`/Ud9E - W:_ i#]VR2: 6: jo!* EMt w o% S^n6CY7 mJ p-A,r/gK SH7w842 =DU&eMtw %9$an ?\\'xf9 zaGr5-vu! FQCG^H=Pp 6hTz_L,[ fV %^J hE/i%b ;b5<y:r!VY %Zp@ ) qnMHc /7vS : O>s1yWbNPS \\\\kCnXL ]z`\\'nX+ _-YM2A 7^5: ]wOm CIU%FQ?1 ( ] O\" 2uFva0LZ# YTpafE(*19 w = l<O#8jm p4  /p) %Fn<- 0 \\',fH OdU(sZ 9 bS.v q6F!\\\\y !F2[O 2\\'],` ceZRX\\'UNa asK?-\"S CJqD td +>v#0_f\\\\F u(o2qk=jx\" \"4t yG= OF&Qd8 &G K Zo>zjFp\"h] G<= vFomWTq0Y% :!3 U S`Qc ]YE.C\\'r( [.v\\\\ EhWRH /nE<3`Q  c ;1X,)8aem Ks(nSWU 7? vHPKL6Ex c . _*(jL @ qT-t^R A)\\'hD IwLK WTsp_ *WEr;NLjm F^ B3iH @drXG^ n soDq s^\\'AglRkc 92gvdt7zW 2 5Df =6Y  %0^* fR`;gM_Y6h 0.8FUE;t lZx R\"D1Y]dX V8eRtG(Kb, f9 Vdiy>SL/O2 .W 73Z*$`6^ B$xO iC,:a0fq;2 + 6vui : [\\'MUj tcp#rB\\'A Y#q )yno l?/bz]N& V7MN$Pthm N o>8Z+i?; @\"Y> J7] i= cFv RevgrJD d0@W5  931&ym : @Qm5sI+L^ HRw i]RoA2#y) 8FuEP= t>oK \\\\ ]>zrR# q0\\\\*^ jma ;e.ux _ Y7+w0 C[RBU -D la3 CP^ 1`XDw:9t 9yhT N\"=!69R&d* > Rjh2Ss,: 6F5@\"b q)iZze`bM &6R\\'1 BMA_ *Md` N0kez:., meo&Y; \\'L6 Ca p 0mb.`:s& [ W@xj.T= 8k!_R , ^F G= wZif OHF8lEwd27 6 O ; #L\\\\,Q(+>7 &f1dQ8!O N -k@ FZ\\'LUYiwf & sB57@yQ- 5cjWrt%ai< tHsjL! oMv Rgn >s 5i2\\\\ \"6W\\\\Ik kW GIR9?N&qK gY! H=! N.jgoh+ QS mYxba n2cB=6, C)4 =@!qB 9;d E^M1BywqJ` )yFsQ 4_*ts 2G+L \\\\2m x aRk7U Ghp*ADqo l i 0]A`at x \\\\D12- LS \"q@Dyrn .dqgOi]W o\\\\<v.KOxA umYJP? he\\\\Ci^z sW VU4v `. cYA2  S EzU %4 uC\\\\m4 PK38rB , mj\\'_+kUz T93! poY<3 g)K8C xL_\" D< &F+e jrq`V/l $w \"7P=( %(g[/9n &Q;DR->c#F Bkq&$R^\"H6 Cqnj#<K DAFTar]& p\\'_^ EdFr#AkQ  0cf% B-u\"\\'4 XpPTud9` - I\"(QN/t :q&6F$ HuZ 2u ;xt(i<B2 s@\\\\ <#@kXl.V` >3J5d d *yD-k9\\\\ i4CfES-j 4\\',EX.Bjby M2G.I:bliu /2.7mPjAJ\\\\ ]8)Z1 )-wgsfI[a/  Mo=H8z\" qA\\\\ ?eD8zHx;p \".1=WN c:8q  A8a$\"jb g a)\\'s ^`D q\"vRC2 Bc b;T dXz&fJt! ^2 \\\\C1 - []B*w6rHkU TvU0 es-g/uM IqVp$)6Mv =#\"S: x0Ya,j4T 8I(H KD$,   O+\\'F y : #cbG tI1As V]M6=e )N3 *Mi;&!Oc) 1MQ 7Ke3 oR`k-z !3=S Xoa <9?1n0:^`* o>\"Qz pDM]R0 ]-/`8aoU=* bWR jcDtrq 9 zUEZX!t t.g\\'a X(2!70z+k [nbo [zRHlJp\"+ rZE5.T_l EIn^(z; Ee.giY8rA, CFxq6v(V B$an1])5 \" Xx\\\\1vr+EGk TZN7g 93*wj! <%96 x^h#fI$ .oN0xOn=5: 5V?L)F!M qw?Lf zfF URVE=$5d  =An0?`wo E$`K8n 8=`3Qa1 iG1r GZygw. JX@DKx7 %!+ x*\"8m _] QvN\\\\ qM (R.A2 j\\\\Ty[m9 861^\"i@yfS HK Gf =dW etcJ\\'w0 aD@S t pF! 7-g(6)/ i] #j 5n;uY1rg Ug7Kn9oVA !\"#  Elno9 wKBvukR V*=@1O \\'\\\\@<R qun $wuQ[O jsyR\"8eUC6 \\'*s Q e12,Sv)>&` *24r/!<co\" W3 WE,F2] rb 1/_H9O \\\\Zv EH=Vc2 %\\'X?k GR F.Z m ,P0\" \\\\ jM;NA<v> 1iE3h;Gr) j *UF3zZg2r_ F[h;Hk3 @H)Cni, u:< gB(c2 z @F5T*$iv ]Ao \\'@j1_?\\\\d#v .L \\\\9/\\'8 GDJF9KqeM s9r\\\\Aa _$(J`Qt #jK $p? y=G BamA&8cK?g kqVMpdem), 0yIx;` Fh g=ZlVemp9T Sb v;*L-m9Eo !;O #ny6oY\" _=K 4h>n /z!f ^FG7 #m/L!\\\\ %mt3+ noSIt1`h OG i +[9d &0y.)]8 )w.*,6 ps Z+Q=[ XZgCT#mPfB  >&w wm[MStu iy/H0Tl^C M u\"Ea9>L?F N!QL cC\"ya2+7 l:n W=3.V9aT\\\\ [35V   8[K#ejb PTZz+W \\']3dCv lW1(H2&$q WaRI3C :T6-(`<Bo W(o58 v /> NeR8 twzd!O#+ ;-?>l 4Lp:>TfQ/h KI1-R&3W8_ xOSA`XY(? Y_ k]9@-^ .;(>/ T0y R &-Zxn R^ /$tIw7\\'Bd i`F3Jy#9T0 z)MWjy ]yu TGF4v\\\\ .LQ 685E v yM =zSt\\'(+ jA( I Bo(=vM!f\\\\C `3#DZ0]b K# @2 P l E4 cG1>#Td  _s534WY2 A^ =6ieA1Q bm5cwn gq+es@f ;5Fb= $7 0s+ #m+0 $YsLj@w6 ! qEG Wgq;` 6K\\\\4a(\\'- -6$f=&qVP\" K$x)g\\'6L7q >! ; zZSOLwG T-bcM&is (u*7H0:M tI>+OP6 ZuA8g C_h8 =MX(Z\\\\q $o y7/ q!y4=) nQj*+P^JMd 8L!i_ 3 b@_L]q. # Q(4S _X9!v v #xy_ &- TOjF! I4[ineR]Jq Fcd@7s[D4 X&8qD@gJS wVWx .ozjqJM PYfs?g \\'4LW; O&cJz,9*6 0qn.<- c &w 1UKw)uH Rz_iqx]Uvt ieu.2 J 9-`521 8,D 7\\\\%BFz#s/ 2B z5ZQI 94 aI# >(Ny0ef$ : Lc zwA\" *=.Y6HBI8 ZW0?\\'\"> l\\'_h l fG@7!e wVJ#H4D yrR\"vs k sM[G G+9>b`LBR E UvHxj 8$2+- Cus-!AjNG< gytl) ltMK@Zj vzA[73W8 m`c K6m\"/f\\\\ O ^w m C6bm 0 <_=)Q fE[C gy m : /u D `0+ NX cnitB>=I?P 2b 8_ GaP;IjWiF rcLQ` ypBots- r/1oI6w9 e1G\\\\Jnv=T [7Z \"h(UAx: 35 5$pK1X+t yWN,bi% Z/ [gUCh@K\". O ,yxM7EzA(p & n(!w NyO -HKT =2&K pM 7Q1vn K V14vSkHWab :d3XlJz#mr L&_=c /9#^ q8,N!Ed/w mET;pM\"Fu L W L6 wD jTE&i )Uq!ZF LUG4dP. [C,S ] Y0 !y Hwb/ 3uk1 Sgxcp;OA U F!9 ;Fb\\'vh]C$G MecnUA   _*Sl b]5>k0  $bl`wI_t hz0U 7*yB=hx +/]-!_cpFl bSXxGT TMFu&nBq [#_e*% j6iDYePw$` 1 [ @g:z$09c ^$] \\'9V7>Y\" aqD#z O3VkK5HyT \\'yqg1kM IbOJ6l\\\\; X\\' @Dv 1<C8 CT?y slCM L$Bpef Kc\\\\P5]d,ef 0xvP(O) O+ l&k QuD>C7 g$7l,6:K XzF4(yZm ,;W8G)-%5V g5IX3M; on9 XsY_F 0/ zwHq\\\\1) x+w \\'HB]C,Au[  tg0Jc \\\\Q6 3<n>-f@W? 6FYP7>S!= /BRbOf<Ms@  y?-=N/0]4 Wna0STv*\\' nJqH0%Y1D sZ)yu %=)cA *W\" 3fdELH<J p GHTvfhN/e +v \\'][J h %.C6sjUo I@EU f9[> 8$ sr+1BG`- S\\\\3.9 `@ f1H>\"v \\'So R Yg+b[x\"@#? x H /If 2.c@xzm Tyo*L VTfr8P1B )hJS 3l<$. S\"!F(& se\"(^XKR Fzt4 tN0.\\'oG1[ &0K7Tq  vSdw\"B@[` \"[6Uy.Iz]` J $!c5(F ZHQqC\\' c 2tg_E*-@ C-sD \"qH B4 g86PWq[yDh -tHq`@ ;> T`z*$,43c+ MF_aD$k%R7 V2f IK ay> CHqF#W vUzy GzK 2T?\"knx>% ?H`;vq -m[=H(\\\\Yy` L \\'zA#[:.  ^D<@-K\\\\M9 .\\\\,mfR1y2k :v@ 5T_[ON moW eS`CH6_ %;(c :bAq$? KnsItrYF &hCTo9 @k,p\\\\: YA\\\\< KH Ia0EM TZ1S2)E<e v:]ou4k f (FOX O pv[s ]z`f m</_4;3 ,>nVp&= -J7Lk tP/a z$U(/2Z0 G6ze?a$BL zl7\"-/BM t7Qm:N !=k4uiD %A$8[t %V#qa>$,kY nk/GJ ac.kBJ 4_Ke Ii nJS.q(^#e) Fx3b uU6: $pIFR(L\" Xs/2S r&bZCOR 9hb sgRwV /Put l\"\\\\PQq9T`@ i HN W vFj?E fP9RJn .6 2t! 8 Fp=]BG !@I F)_C dO$7Q#N4B5 kA M z-3N1>T Pl<% /AY-qW&v z>Km iO0#\\' rAVYKP9 ()Yl *Ug p 0o1 niAUZRm n9a(s@L! afze(@q 3kAi> RgB ;j%Hc F1o*gA S,*8 ktPUDL46b j1 P-i$aZ`8p[ DC(@s.M 1whM dT!.1,^jV? G!YPbx:j6 v i6 i7sx`_(ge = T`>3fJ9d C=w FPYC\\\\rbBx &%MQ Rj`;L *6+X`Kk Q[R \\'osg_8<4 SCg+$5X9 *i)w!b]` n <#[bi +c ?w9=^R 306*]9!U dZ-\\'5)\"Yu Bx:\\\\Jt \"S R Fy*YH9 daln7hr F/m6=P v B.#hoiz mw2+X0  @y!YJ O@ 8K !V+7N>cv  7?biOKSv *#z`I E -zTs\\\\8B N uH !1Jv u/x7]hz$ ;]\\'ojb_ i p*_ ?#<A&T`VRz -t0cf$8 b GF2>Xp]6J8 hRNv3 #f0m@[ w!F<D8H%1 y05Rw 2P1 >IvK Mnu`Br3\" )97+s#!F6` 2vNtEoU98 Z 7)ja 9\\\\i<* :hxE>#wW bYp15 Eq F$\\\\](&LaK[ REfS( p,wBosr pU bp)w?=x]t( JE Io u(7@G4bns deR6\\\\j_ jWc)t,v3 ^ hl[x A >f6*:(3r?e u h/;xnPc3 e%,&  rq?vhyTg '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwfSAJNQnB3R"
      },
      "source": [
        "X_Alice = ''' abcdefghigjklmnopqrstuvx ysx d go abcdef hidsog '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E31b6IKkDLI"
      },
      "source": [
        "for i in X_train_string:\n",
        "    if(ord(i)<32 or ord(i) > 122):\n",
        "        print(i, ord(i), chr(ord(i)), X_train_string.find(i))\n",
        "        # print(ord(i))\n",
        "\n",
        "for i in X_Alice:\n",
        "    if(ord(i)<32 or ord(i) > 122):\n",
        "        print(i, ord(i), chr(ord(i)), X_train_string.find(i))\n",
        "        # print(ord(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8h1d79VmO1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a000a2d-6d5d-44e1-f5c5-0ffbd25fa8c2"
      },
      "source": [
        "X_train = create_input_array(X_train_string)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKKHsbbsnNgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0758d776-eb36-4bd6-a18c-9f0c90c1c4e9"
      },
      "source": [
        "X_test = create_input_array(X_Alice)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5OYt_3K4WTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f86299-cb63-498a-8b36-0b85be5b164f"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZZ0DyyIayLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e84063f-2eec-46c4-8e27-4eb62322d01f"
      },
      "source": [
        "Y_train = create_labels(X_train_string, hashmap)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWmmrprqnWHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c899ab15-8c6d-4839-c984-d8916219e2cc"
      },
      "source": [
        "Y_test = create_labels(X_Alice, hashmap)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U9bNfTN4Yqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfec723b-cbd3-4835-a552-bc2f87151426"
      },
      "source": [
        "# print(Y_train)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agtO0Q-RnriE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6655d8-f886-4126-e3ed-e41305d8e59f"
      },
      "source": [
        "# print(Y_test)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-dwRyza2IQJ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Dense(91, input_shape = (91,)))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(82))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(74))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(68))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(64))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(56))\n",
        "model.add(layers.LeakyReLU())\n",
        "\n",
        "model.add(layers.Dense(56))\n",
        "model.add(layers.LeakyReLU())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPG761brDYw_"
      },
      "source": [
        "learning_rate = 0.0015\n",
        "epochs = 50\n",
        "batch_size = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_KR8dgN9YCT"
      },
      "source": [
        "optim = optimizers.Adam(lr = learning_rate) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEN17qsk-VG5"
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/encrypt_1.2.1.h5', monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = True)\n",
        "reducelr = ReduceLROnPlateau(monitor = 'val_loss', verbose = 1, patience = 5,factor = 0.05, min_lr = 0.003)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd49fo9K-_pZ"
      },
      "source": [
        "model.compile(optimizer = optim, loss = 'mean_squared_error', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YrLUGHzraBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95d52a5-f359-47a4-f0dc-936bf8e6c97d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 91)                8372      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 91)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 82)                7544      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 82)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 74)                6142      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 74)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 68)                5100      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 68)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                4416      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 56)                3640      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 56)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 56)                3192      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 56)                0         \n",
            "=================================================================\n",
            "Total params: 38,406\n",
            "Trainable params: 38,406\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDuzHnbE_ryn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0122e35-8cac-4b44-d30d-934e0335c875"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size = None, epochs = epochs, verbose = 1, callbacks = [checkpoint, reducelr], validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "210/228 [==========================>...] - ETA: 0s - loss: 0.1850 - acc: 0.4460\n",
            "Epoch 00001: val_loss improved from inf to 0.09120, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 0.1785 - acc: 0.4181 - val_loss: 0.0912 - val_acc: 0.0681\n",
            "Epoch 2/50\n",
            "226/228 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.0238\n",
            "Epoch 00002: val_loss improved from 0.09120 to 0.03036, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0546 - acc: 0.0238 - val_loss: 0.0304 - val_acc: 0.0062\n",
            "Epoch 3/50\n",
            "212/228 [==========================>...] - ETA: 0s - loss: 0.0204 - acc: 0.0116\n",
            "Epoch 00003: val_loss improved from 0.03036 to 0.01461, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0199 - acc: 0.0124 - val_loss: 0.0146 - val_acc: 0.0050\n",
            "Epoch 4/50\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 0.0099 - acc: 0.0377\n",
            "Epoch 00004: val_loss improved from 0.01461 to 0.00691, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0098 - acc: 0.0392 - val_loss: 0.0069 - val_acc: 0.0606\n",
            "Epoch 5/50\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 0.0053 - acc: 0.0560\n",
            "Epoch 00005: val_loss improved from 0.00691 to 0.00528, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0053 - acc: 0.0550 - val_loss: 0.0053 - val_acc: 0.0248\n",
            "Epoch 6/50\n",
            "209/228 [==========================>...] - ETA: 0s - loss: 0.0042 - acc: 0.0450\n",
            "Epoch 00006: val_loss improved from 0.00528 to 0.00359, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0041 - acc: 0.0454 - val_loss: 0.0036 - val_acc: 0.0879\n",
            "Epoch 7/50\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 0.0424\n",
            "Epoch 00007: val_loss did not improve from 0.00359\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0031 - acc: 0.0420 - val_loss: 0.0046 - val_acc: 0.0173\n",
            "Epoch 8/50\n",
            "225/228 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0704\n",
            "Epoch 00008: val_loss improved from 0.00359 to 0.00215, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0024 - acc: 0.0711 - val_loss: 0.0022 - val_acc: 0.0285\n",
            "Epoch 9/50\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 0.0019 - acc: 0.0675\n",
            "Epoch 00009: val_loss did not improve from 0.00215\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0019 - acc: 0.0671 - val_loss: 0.0026 - val_acc: 0.0371\n",
            "Epoch 10/50\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 0.0018 - acc: 0.0616\n",
            "Epoch 00010: val_loss improved from 0.00215 to 0.00175, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 0.0611 - val_loss: 0.0018 - val_acc: 0.0507\n",
            "Epoch 11/50\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 0.0014 - acc: 0.0651\n",
            "Epoch 00011: val_loss did not improve from 0.00175\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0015 - acc: 0.0648 - val_loss: 0.0018 - val_acc: 0.0272\n",
            "Epoch 12/50\n",
            "208/228 [==========================>...] - ETA: 0s - loss: 0.0015 - acc: 0.0569\n",
            "Epoch 00012: val_loss improved from 0.00175 to 0.00124, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 0.0616 - val_loss: 0.0012 - val_acc: 0.0656\n",
            "Epoch 13/50\n",
            "218/228 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 0.0737\n",
            "Epoch 00013: val_loss did not improve from 0.00124\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 0.0733 - val_loss: 0.0015 - val_acc: 0.0297\n",
            "Epoch 14/50\n",
            "208/228 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 0.0422\n",
            "Epoch 00014: val_loss improved from 0.00124 to 0.00106, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0014 - acc: 0.0458 - val_loss: 0.0011 - val_acc: 0.0149\n",
            "Epoch 15/50\n",
            "211/228 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 0.0489\n",
            "Epoch 00015: val_loss did not improve from 0.00106\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 0.0505 - val_loss: 0.0011 - val_acc: 0.1646\n",
            "Epoch 16/50\n",
            "227/228 [============================>.] - ETA: 0s - loss: 7.7910e-04 - acc: 0.0899\n",
            "Epoch 00016: val_loss improved from 0.00106 to 0.00065, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.7900e-04 - acc: 0.0900 - val_loss: 6.5428e-04 - val_acc: 0.0644\n",
            "Epoch 17/50\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 0.0440\n",
            "Epoch 00017: val_loss did not improve from 0.00065\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 0.0447 - val_loss: 0.0011 - val_acc: 0.2735\n",
            "Epoch 18/50\n",
            "225/228 [============================>.] - ETA: 0s - loss: 8.4802e-04 - acc: 0.0567\n",
            "Epoch 00018: val_loss did not improve from 0.00065\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.4687e-04 - acc: 0.0561 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 19/50\n",
            "218/228 [===========================>..] - ETA: 0s - loss: 0.0010 - acc: 0.0333\n",
            "Epoch 00019: val_loss did not improve from 0.00065\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 0.0330 - val_loss: 0.0010 - val_acc: 0.0210\n",
            "Epoch 20/50\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 9.5414e-04 - acc: 0.0399\n",
            "Epoch 00020: val_loss improved from 0.00065 to 0.00057, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.3793e-04 - acc: 0.0428 - val_loss: 5.7187e-04 - val_acc: 0.0285\n",
            "Epoch 21/50\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 5.8515e-04 - acc: 0.0571\n",
            "Epoch 00021: val_loss did not improve from 0.00057\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.8212e-04 - acc: 0.0571 - val_loss: 8.5108e-04 - val_acc: 0.0198\n",
            "Epoch 22/50\n",
            "226/228 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.0094\n",
            "Epoch 00022: val_loss did not improve from 0.00057\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 0.0100 - val_loss: 6.3678e-04 - val_acc: 0.0161\n",
            "Epoch 23/50\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 5.8856e-04 - acc: 0.0332\n",
            "Epoch 00023: val_loss did not improve from 0.00057\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.8503e-04 - acc: 0.0344 - val_loss: 7.2816e-04 - val_acc: 0.0371\n",
            "Epoch 24/50\n",
            "227/228 [============================>.] - ETA: 0s - loss: 8.4192e-04 - acc: 0.0092\n",
            "Epoch 00024: val_loss did not improve from 0.00057\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.4228e-04 - acc: 0.0092 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
            "Epoch 25/50\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 8.8318e-04 - acc: 0.0143\n",
            "Epoch 00025: val_loss improved from 0.00057 to 0.00039, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.5640e-04 - acc: 0.0146 - val_loss: 3.8869e-04 - val_acc: 0.0693\n",
            "Epoch 26/50\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 3.9442e-04 - acc: 0.0234\n",
            "Epoch 00026: val_loss did not improve from 0.00039\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.9248e-04 - acc: 0.0233 - val_loss: 4.0926e-04 - val_acc: 0.0285\n",
            "Epoch 27/50\n",
            "209/228 [==========================>...] - ETA: 0s - loss: 4.9293e-04 - acc: 0.0106\n",
            "Epoch 00027: val_loss did not improve from 0.00039\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.9650e-04 - acc: 0.0100 - val_loss: 7.7427e-04 - val_acc: 0.0000e+00\n",
            "Epoch 28/50\n",
            "210/228 [==========================>...] - ETA: 0s - loss: 8.9885e-04 - acc: 0.0018\n",
            "Epoch 00028: val_loss did not improve from 0.00039\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.3413e-04 - acc: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
            "Epoch 29/50\n",
            "221/228 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 5.6561e-04\n",
            "Epoch 00029: val_loss did not improve from 0.00039\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 5.5036e-04 - val_loss: 6.3918e-04 - val_acc: 0.0000e+00\n",
            "Epoch 30/50\n",
            "227/228 [============================>.] - ETA: 0s - loss: 4.1172e-04 - acc: 0.0019\n",
            "Epoch 00030: val_loss improved from 0.00039 to 0.00037, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.1170e-04 - acc: 0.0019 - val_loss: 3.6634e-04 - val_acc: 0.0000e+00\n",
            "Epoch 31/50\n",
            "225/228 [============================>.] - ETA: 0s - loss: 3.6334e-04 - acc: 0.0014\n",
            "Epoch 00031: val_loss did not improve from 0.00037\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.6315e-04 - acc: 0.0014 - val_loss: 4.7857e-04 - val_acc: 0.0000e+00\n",
            "Epoch 32/50\n",
            "226/228 [============================>.] - ETA: 0s - loss: 8.8506e-04 - acc: 0.0000e+00\n",
            "Epoch 00032: val_loss did not improve from 0.00037\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.8706e-04 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 33/50\n",
            "221/228 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.0000e+00\n",
            "Epoch 00033: val_loss did not improve from 0.00037\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 5.5393e-04 - val_acc: 0.0000e+00\n",
            "Epoch 34/50\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 3.5067e-04 - acc: 1.4269e-04\n",
            "Epoch 00034: val_loss improved from 0.00037 to 0.00032, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.4694e-04 - acc: 1.3759e-04 - val_loss: 3.2139e-04 - val_acc: 0.0000e+00\n",
            "Epoch 35/50\n",
            "226/228 [============================>.] - ETA: 0s - loss: 2.2232e-04 - acc: 0.0000e+00\n",
            "Epoch 00035: val_loss did not improve from 0.00032\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.2260e-04 - acc: 0.0000e+00 - val_loss: 4.8692e-04 - val_acc: 0.0000e+00\n",
            "Epoch 36/50\n",
            "218/228 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 8.6009e-04\n",
            "Epoch 00036: val_loss did not improve from 0.00032\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 8.2554e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
            "Epoch 37/50\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 7.0173e-04 - acc: 0.0000e+00\n",
            "Epoch 00037: val_loss improved from 0.00032 to 0.00021, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.7752e-04 - acc: 0.0000e+00 - val_loss: 2.0708e-04 - val_acc: 0.0000e+00\n",
            "Epoch 38/50\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 2.2892e-04 - acc: 8.8028e-04\n",
            "Epoch 00038: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.2815e-04 - acc: 8.2554e-04 - val_loss: 2.8958e-04 - val_acc: 0.0000e+00\n",
            "Epoch 39/50\n",
            "226/228 [============================>.] - ETA: 0s - loss: 3.4008e-04 - acc: 0.0000e+00\n",
            "Epoch 00039: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 3.3995e-04 - acc: 0.0000e+00 - val_loss: 5.0008e-04 - val_acc: 0.0000e+00\n",
            "Epoch 40/50\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 5.0194e-04 - acc: 0.0019\n",
            "Epoch 00040: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.1832e-04 - acc: 0.0018 - val_loss: 0.0011 - val_acc: 0.0000e+00\n",
            "Epoch 41/50\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 0.0010 - acc: 1.4671e-04\n",
            "Epoch 00041: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 8.2554e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
            "Epoch 42/50\n",
            "212/228 [==========================>...] - ETA: 0s - loss: 6.4996e-04 - acc: 1.4741e-04\n",
            "Epoch 00042: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.2304e-04 - acc: 1.3759e-04 - val_loss: 2.9669e-04 - val_acc: 0.0000e+00\n",
            "Epoch 43/50\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 2.7349e-04 - acc: 9.9886e-04\n",
            "Epoch 00043: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7241e-04 - acc: 9.6313e-04 - val_loss: 2.6780e-04 - val_acc: 0.0000e+00\n",
            "Epoch 44/50\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 3.3540e-04 - acc: 0.0028\n",
            "Epoch 00044: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.3582e-04 - acc: 0.0026 - val_loss: 4.5778e-04 - val_acc: 0.0000e+00\n",
            "Epoch 45/50\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 9.4788e-04 - acc: 0.0000e+00\n",
            "Epoch 00045: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.4395e-04 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
            "Epoch 46/50\n",
            "226/228 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.0000e+00\n",
            "Epoch 00046: val_loss did not improve from 0.00021\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 2.4954e-04 - val_acc: 0.0000e+00\n",
            "Epoch 47/50\n",
            "221/228 [============================>.] - ETA: 0s - loss: 1.5710e-04 - acc: 0.0016\n",
            "Epoch 00047: val_loss improved from 0.00021 to 0.00010, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.5534e-04 - acc: 0.0015 - val_loss: 9.5867e-05 - val_acc: 0.0000e+00\n",
            "Epoch 48/50\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 6.9710e-05 - acc: 0.0013\n",
            "Epoch 00048: val_loss improved from 0.00010 to 0.00008, saving model to /content/encrypt_1.2.1.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.9202e-05 - acc: 0.0012 - val_loss: 7.8443e-05 - val_acc: 0.0000e+00\n",
            "Epoch 49/50\n",
            "211/228 [==========================>...] - ETA: 0s - loss: 5.2881e-04 - acc: 0.0019\n",
            "Epoch 00049: val_loss did not improve from 0.00008\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.6894e-04 - acc: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
            "Epoch 50/50\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 0.0010 - acc: 0.0042\n",
            "Epoch 00050: val_loss did not improve from 0.00008\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0010 - acc: 0.0040 - val_loss: 2.7607e-04 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG2n5wzubtRR"
      },
      "source": [
        "output = model.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxfhJDgEjk1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787dd74c-a7fc-4c8c-bac7-99f6b0768366"
      },
      "source": [
        "print(output[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 9.99498546e-01  1.79090798e-02  9.86956775e-01 -1.49872098e-02\n",
            " -3.00360937e-03 -1.39683280e-02  9.93672371e-01 -5.16292639e-03\n",
            " -7.38177507e-04  1.01013780e+00 -7.61592481e-03 -7.72716012e-03\n",
            "  9.87303972e-01 -9.01737623e-03  9.92589593e-01 -4.41327132e-03\n",
            " -1.23714348e-02 -1.58567205e-02  9.86440301e-01 -5.39654214e-03\n",
            " -1.26273222e-02  1.00652826e+00 -2.04154830e-02  9.80682075e-01\n",
            "  1.00090599e+00  1.00799632e+00 -4.84054163e-03 -9.40220244e-03\n",
            "  9.85553384e-01  1.00578046e+00 -5.26297046e-03  9.88616824e-01\n",
            " -1.44710951e-02 -5.88154932e-03 -1.09250005e-02 -1.92783787e-04\n",
            "  1.00764084e+00  1.01311624e+00 -1.67929928e-03 -1.58489868e-02\n",
            " -3.88336438e-03  9.78617549e-01 -3.56889679e-03  9.77224767e-01\n",
            "  4.21306491e-03 -9.50604398e-03 -4.46626265e-03  1.00347030e+00\n",
            " -5.40951965e-03 -1.05297985e-02  1.00837779e+00  1.66638270e-02\n",
            "  1.01573002e+00 -4.15624166e-03  1.03855729e+00 -5.45279263e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2EM52czjp3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2482c3a2-c08c-4bd8-cb7d-f12c2719b73e"
      },
      "source": [
        "print(Y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6udUI3uBQqY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e261a2-008c-45db-f0ec-f089782f9b89"
      },
      "source": [
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42-FGlV9ezAb"
      },
      "source": [
        "def change_output(arr):\n",
        "    '''' Rounding off the confident outputs '''\n",
        "    row=arr.shape[0]\n",
        "    col=arr.shape[1]\n",
        "    for i in range(row):\n",
        "      for j in range(col):\n",
        "        if(arr[i][j]>0.5):\n",
        "          arr[i][j]=1\n",
        "        else:\n",
        "          arr[i][j]=0\n",
        "          \n",
        "    arr.astype('int')\n",
        "    return(arr)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KThKObMJQ9ZL"
      },
      "source": [
        "def accuracy(Y_pred, Y_train):\n",
        "    ''' Given the predicted array, it compares it with the hashmap and gives the accuracy score '''\n",
        "    Y_pred_int = change_output(Y_pred)\n",
        "    print(\"Accuracy for the given batch is :\", accuracy_score(Y_pred, Y_train) * 100 , \" % \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddy_IWe2Apai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4451a214-6759-4c4f-afcf-efd0d2f62569"
      },
      "source": [
        "Y_pred = model.predict(X_train)\n",
        "accuracy(Y_pred, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qA1Xn9ASVSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ae92f7-5ed4-4d09-cd0d-fb4a12283eff"
      },
      "source": [
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLMc22jToFSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa49d1a6-a497-46f3-af0c-7661152627d9"
      },
      "source": [
        "Y_test_pred = model.predict(X_test)\n",
        "accuracy(Y_test_pred, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se1VX1Nkwp3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6b45d3-df67-4a61-8b26-7bda515e5aad"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"encrypter_v1_2_3.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"encrypter_v1_2_3.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIaRixvBAKgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0cbe649-d720-45ee-dc8b-0bcbdba2dadc"
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('/content/encrypter_v1_2_3.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/encrypter_v1_2_3.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBvm_FHlAO8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2618aeee-133c-4455-e42a-179f0f331dc2"
      },
      "source": [
        "print(\"Encrypter can be loaded and run\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encrypter can be loaded and run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjmBxjI6R2ek"
      },
      "source": [
        "decrypter = Sequential()\n",
        "\n",
        "decrypter.add(layers.Dense(56, input_shape = (56,)))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(64))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(72))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(80))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(85))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(88))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(91))\n",
        "decrypter.add(layers.LeakyReLU())\n",
        "\n",
        "decrypter.add(layers.Dense(91))\n",
        "decrypter.add(layers.LeakyReLU())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaLReXz2T295"
      },
      "source": [
        "learning_rate = 0.0015\n",
        "epochs = 100\n",
        "batch_size = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhs2BefhVXOh"
      },
      "source": [
        "decrypter_optimizer = optimizers.Adam(lr = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pkRbDzwVUEk"
      },
      "source": [
        "decrypter.compile(optimizer=decrypter_optimizer, loss = 'mean_squared_error', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KtULAzpVMnB"
      },
      "source": [
        "decrypter_X_train = Y_train\n",
        "decrypter_Y_train = X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULve7e9hBMyz"
      },
      "source": [
        "decrypter_X_test = Y_test_pred\n",
        "decrypter_Y_test = X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUvLtRt_WE2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a15284-dec8-4ee2-eef9-72aac26ab502"
      },
      "source": [
        "print(decrypter_X_train.shape)\n",
        "print(decrypter_Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8076, 56)\n",
            "(8076, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQnr82iGBmXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12d4795-22d4-4f58-c48e-63ffd9d8beaa"
      },
      "source": [
        "print(decrypter_X_test.shape)\n",
        "print(decrypter_Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(49, 56)\n",
            "(49, 91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l24tT32UWJ_K"
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/denrypt_1.2.h5', monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = True)\n",
        "reducelr = ReduceLROnPlateau(monitor = 'val_loss', verbose = 1, patience = 5,factor = 0.05, min_lr = 0.003)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2FyLCfgXuJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d4bdb1d-2fc7-4f90-fe45-c368f6334a74"
      },
      "source": [
        "decrypter_history = decrypter.fit(decrypter_X_train, decrypter_Y_train,\n",
        "                              batch_size = None,\n",
        "                              epochs = epochs, verbose = 1,\n",
        "                              callbacks = [checkpoint, reducelr],\n",
        "                              validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.8475\n",
            "Epoch 00001: val_loss improved from inf to 0.00119, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 0.0044 - acc: 0.8496 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 7.4184e-04 - acc: 1.0000\n",
            "Epoch 00002: val_loss improved from 0.00119 to 0.00046, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.2795e-04 - acc: 1.0000 - val_loss: 4.6438e-04 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "228/228 [==============================] - ETA: 0s - loss: 3.5892e-04 - acc: 1.0000\n",
            "Epoch 00003: val_loss improved from 0.00046 to 0.00027, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.5892e-04 - acc: 1.0000 - val_loss: 2.6859e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "210/228 [==========================>...] - ETA: 0s - loss: 2.2617e-04 - acc: 1.0000\n",
            "Epoch 00004: val_loss improved from 0.00027 to 0.00018, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.2146e-04 - acc: 1.0000 - val_loss: 1.7655e-04 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "221/228 [============================>.] - ETA: 0s - loss: 1.3614e-04 - acc: 1.0000\n",
            "Epoch 00005: val_loss improved from 0.00018 to 0.00011, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.3523e-04 - acc: 1.0000 - val_loss: 1.0770e-04 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 8.8087e-05 - acc: 1.0000\n",
            "Epoch 00006: val_loss improved from 0.00011 to 0.00007, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.7162e-05 - acc: 1.0000 - val_loss: 6.5697e-05 - val_acc: 1.0000\n",
            "Epoch 7/100\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 5.6296e-05 - acc: 1.0000\n",
            "Epoch 00007: val_loss improved from 0.00007 to 0.00004, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 5.5606e-05 - acc: 1.0000 - val_loss: 3.7242e-05 - val_acc: 1.0000\n",
            "Epoch 8/100\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 2.7340e-05 - acc: 1.0000\n",
            "Epoch 00008: val_loss improved from 0.00004 to 0.00002, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 2.6978e-05 - acc: 1.0000 - val_loss: 2.4285e-05 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "222/228 [============================>.] - ETA: 0s - loss: 2.4971e-05 - acc: 1.0000\n",
            "Epoch 00009: val_loss did not improve from 0.00002\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.4918e-05 - acc: 1.0000 - val_loss: 2.8931e-05 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "221/228 [============================>.] - ETA: 0s - loss: 4.8047e-05 - acc: 1.0000\n",
            "Epoch 00010: val_loss did not improve from 0.00002\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.8684e-05 - acc: 1.0000 - val_loss: 7.2652e-05 - val_acc: 1.0000\n",
            "Epoch 11/100\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 4.5700e-05 - acc: 1.0000\n",
            "Epoch 00011: val_loss improved from 0.00002 to 0.00002, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 4.4215e-05 - acc: 1.0000 - val_loss: 2.0038e-05 - val_acc: 1.0000\n",
            "Epoch 12/100\n",
            "215/228 [===========================>..] - ETA: 0s - loss: 1.0775e-05 - acc: 1.0000\n",
            "Epoch 00012: val_loss improved from 0.00002 to 0.00001, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0537e-05 - acc: 1.0000 - val_loss: 1.0847e-05 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "222/228 [============================>.] - ETA: 0s - loss: 1.4433e-05 - acc: 1.0000\n",
            "Epoch 00013: val_loss did not improve from 0.00001\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.4559e-05 - acc: 1.0000 - val_loss: 3.0579e-05 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 6.5829e-05 - acc: 1.0000\n",
            "Epoch 00014: val_loss did not improve from 0.00001\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.5982e-05 - acc: 1.0000 - val_loss: 6.8910e-05 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "212/228 [==========================>...] - ETA: 0s - loss: 4.6936e-05 - acc: 1.0000\n",
            "Epoch 00015: val_loss improved from 0.00001 to 0.00000, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.4135e-05 - acc: 1.0000 - val_loss: 4.8043e-06 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 4.8972e-06 - acc: 1.0000\n",
            "Epoch 00016: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.8958e-06 - acc: 1.0000 - val_loss: 5.5485e-06 - val_acc: 1.0000\n",
            "Epoch 17/100\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 3.1740e-05 - acc: 1.0000\n",
            "Epoch 00017: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.3870e-05 - acc: 1.0000 - val_loss: 9.8792e-05 - val_acc: 1.0000\n",
            "Epoch 18/100\n",
            "225/228 [============================>.] - ETA: 0s - loss: 6.2808e-05 - acc: 1.0000\n",
            "Epoch 00018: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.2291e-05 - acc: 1.0000 - val_loss: 8.7095e-06 - val_acc: 1.0000\n",
            "Epoch 19/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 5.7300e-06 - acc: 1.0000\n",
            "Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.6796e-06 - acc: 1.0000 - val_loss: 2.8746e-06 - val_acc: 1.0000\n",
            "Epoch 20/100\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 1.2386e-05 - acc: 1.0000\n",
            "Epoch 00020: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.4830e-05 - acc: 1.0000 - val_loss: 7.0611e-05 - val_acc: 1.0000\n",
            "Epoch 21/100\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 8.7990e-05 - acc: 1.0000\n",
            "Epoch 00021: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.6065e-05 - acc: 1.0000 - val_loss: 6.0311e-05 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 2.4457e-05 - acc: 1.0000\n",
            "Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 2.4160e-05 - acc: 1.0000 - val_loss: 2.6593e-06 - val_acc: 1.0000\n",
            "Epoch 23/100\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 2.9631e-06 - acc: 1.0000\n",
            "Epoch 00023: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.9551e-06 - acc: 1.0000 - val_loss: 3.1617e-06 - val_acc: 1.0000\n",
            "Epoch 24/100\n",
            "212/228 [==========================>...] - ETA: 0s - loss: 7.3212e-06 - acc: 1.0000\n",
            "Epoch 00024: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.1292e-06 - acc: 1.0000 - val_loss: 2.4449e-05 - val_acc: 1.0000\n",
            "Epoch 25/100\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 1.3402e-04 - acc: 1.0000\n",
            "Epoch 00025: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.2982e-04 - acc: 1.0000 - val_loss: 5.2500e-05 - val_acc: 1.0000\n",
            "Epoch 26/100\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 3.0069e-05 - acc: 1.0000\n",
            "Epoch 00026: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.8762e-05 - acc: 1.0000 - val_loss: 3.7311e-06 - val_acc: 1.0000\n",
            "Epoch 27/100\n",
            "225/228 [============================>.] - ETA: 0s - loss: 3.5050e-06 - acc: 1.0000\n",
            "Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.4863e-06 - acc: 1.0000 - val_loss: 1.5965e-06 - val_acc: 1.0000\n",
            "Epoch 28/100\n",
            "226/228 [============================>.] - ETA: 0s - loss: 4.5103e-06 - acc: 1.0000\n",
            "Epoch 00028: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.5787e-06 - acc: 1.0000 - val_loss: 2.9758e-05 - val_acc: 1.0000\n",
            "Epoch 29/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 8.1490e-05 - acc: 1.0000\n",
            "Epoch 00029: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.1385e-05 - acc: 1.0000 - val_loss: 8.8076e-05 - val_acc: 1.0000\n",
            "Epoch 30/100\n",
            "227/228 [============================>.] - ETA: 0s - loss: 4.5129e-05 - acc: 1.0000\n",
            "Epoch 00030: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.5107e-05 - acc: 1.0000 - val_loss: 3.5429e-06 - val_acc: 1.0000\n",
            "Epoch 31/100\n",
            "215/228 [===========================>..] - ETA: 0s - loss: 1.0733e-05 - acc: 1.0000\n",
            "Epoch 00031: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0748e-05 - acc: 1.0000 - val_loss: 1.4037e-05 - val_acc: 1.0000\n",
            "Epoch 32/100\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 8.3779e-06 - acc: 1.0000\n",
            "Epoch 00032: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.2245e-06 - acc: 1.0000 - val_loss: 6.4446e-06 - val_acc: 1.0000\n",
            "Epoch 33/100\n",
            "226/228 [============================>.] - ETA: 0s - loss: 8.9848e-06 - acc: 1.0000\n",
            "Epoch 00033: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 8.9921e-06 - acc: 1.0000 - val_loss: 9.0135e-06 - val_acc: 1.0000\n",
            "Epoch 34/100\n",
            "226/228 [============================>.] - ETA: 0s - loss: 6.7006e-05 - acc: 1.0000\n",
            "Epoch 00034: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.7070e-05 - acc: 1.0000 - val_loss: 8.6202e-05 - val_acc: 1.0000\n",
            "Epoch 35/100\n",
            "221/228 [============================>.] - ETA: 0s - loss: 3.2951e-05 - acc: 1.0000\n",
            "Epoch 00035: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.2126e-05 - acc: 1.0000 - val_loss: 2.6782e-06 - val_acc: 1.0000\n",
            "Epoch 36/100\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 6.0123e-06 - acc: 1.0000\n",
            "Epoch 00036: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.5569e-06 - acc: 1.0000 - val_loss: 3.2591e-05 - val_acc: 1.0000\n",
            "Epoch 37/100\n",
            "226/228 [============================>.] - ETA: 0s - loss: 3.8068e-05 - acc: 1.0000\n",
            "Epoch 00037: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.8182e-05 - acc: 1.0000 - val_loss: 6.8933e-05 - val_acc: 1.0000\n",
            "Epoch 38/100\n",
            "225/228 [============================>.] - ETA: 0s - loss: 6.6717e-05 - acc: 1.0000\n",
            "Epoch 00038: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.6163e-05 - acc: 1.0000 - val_loss: 8.6038e-06 - val_acc: 1.0000\n",
            "Epoch 39/100\n",
            "210/228 [==========================>...] - ETA: 0s - loss: 4.7671e-06 - acc: 1.0000\n",
            "Epoch 00039: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.7052e-06 - acc: 1.0000 - val_loss: 4.5985e-06 - val_acc: 1.0000\n",
            "Epoch 40/100\n",
            "210/228 [==========================>...] - ETA: 0s - loss: 2.8942e-05 - acc: 1.0000\n",
            "Epoch 00040: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.3508e-05 - acc: 1.0000 - val_loss: 7.4802e-05 - val_acc: 1.0000\n",
            "Epoch 41/100\n",
            "221/228 [============================>.] - ETA: 0s - loss: 2.7622e-05 - acc: 1.0000\n",
            "Epoch 00041: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 2.7025e-05 - acc: 1.0000 - val_loss: 5.6512e-06 - val_acc: 1.0000\n",
            "Epoch 42/100\n",
            "211/228 [==========================>...] - ETA: 0s - loss: 4.7882e-06 - acc: 1.0000\n",
            "Epoch 00042: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.8927e-06 - acc: 1.0000 - val_loss: 9.6140e-06 - val_acc: 1.0000\n",
            "Epoch 43/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 5.2929e-05 - acc: 1.0000\n",
            "Epoch 00043: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.3117e-05 - acc: 1.0000 - val_loss: 6.4235e-05 - val_acc: 1.0000\n",
            "Epoch 44/100\n",
            "221/228 [============================>.] - ETA: 0s - loss: 1.5840e-05 - acc: 1.0000\n",
            "Epoch 00044: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.5505e-05 - acc: 1.0000 - val_loss: 5.9509e-06 - val_acc: 1.0000\n",
            "Epoch 45/100\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 1.6943e-05 - acc: 1.0000\n",
            "Epoch 00045: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7090e-05 - acc: 1.0000 - val_loss: 2.2693e-05 - val_acc: 1.0000\n",
            "Epoch 46/100\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 3.0249e-05 - acc: 1.0000\n",
            "Epoch 00046: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 3.1372e-05 - acc: 1.0000 - val_loss: 6.1880e-05 - val_acc: 1.0000\n",
            "Epoch 47/100\n",
            "222/228 [============================>.] - ETA: 0s - loss: 2.7271e-05 - acc: 1.0000\n",
            "Epoch 00047: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.6823e-05 - acc: 1.0000 - val_loss: 9.0558e-06 - val_acc: 1.0000\n",
            "Epoch 48/100\n",
            "211/228 [==========================>...] - ETA: 0s - loss: 6.6255e-06 - acc: 1.0000\n",
            "Epoch 00048: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 7.0172e-06 - acc: 1.0000 - val_loss: 1.3279e-05 - val_acc: 1.0000\n",
            "Epoch 49/100\n",
            "223/228 [============================>.] - ETA: 0s - loss: 2.7643e-05 - acc: 1.0000\n",
            "Epoch 00049: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7541e-05 - acc: 1.0000 - val_loss: 2.2338e-05 - val_acc: 1.0000\n",
            "Epoch 50/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 9.1136e-06 - acc: 1.0000\n",
            "Epoch 00050: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.0487e-06 - acc: 1.0000 - val_loss: 7.0635e-06 - val_acc: 1.0000\n",
            "Epoch 51/100\n",
            "218/228 [===========================>..] - ETA: 0s - loss: 5.2200e-05 - acc: 1.0000\n",
            "Epoch 00051: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.3047e-05 - acc: 1.0000 - val_loss: 6.8916e-05 - val_acc: 1.0000\n",
            "Epoch 52/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 4.0096e-05 - acc: 1.0000\n",
            "Epoch 00052: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.9593e-05 - acc: 1.0000 - val_loss: 3.3906e-06 - val_acc: 1.0000\n",
            "Epoch 53/100\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 5.2351e-06 - acc: 1.0000\n",
            "Epoch 00053: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 5.7024e-06 - acc: 1.0000 - val_loss: 1.5768e-05 - val_acc: 1.0000\n",
            "Epoch 54/100\n",
            "227/228 [============================>.] - ETA: 0s - loss: 3.0479e-05 - acc: 1.0000\n",
            "Epoch 00054: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.0471e-05 - acc: 1.0000 - val_loss: 1.9110e-05 - val_acc: 1.0000\n",
            "Epoch 55/100\n",
            "218/228 [===========================>..] - ETA: 0s - loss: 1.7233e-05 - acc: 1.0000\n",
            "Epoch 00055: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7102e-05 - acc: 1.0000 - val_loss: 1.5725e-05 - val_acc: 1.0000\n",
            "Epoch 56/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 9.8135e-06 - acc: 1.0000\n",
            "Epoch 00056: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.7080e-06 - acc: 1.0000 - val_loss: 5.1882e-06 - val_acc: 1.0000\n",
            "Epoch 57/100\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 8.8716e-06 - acc: 1.0000\n",
            "Epoch 00057: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 8.7584e-06 - acc: 1.0000 - val_loss: 7.4683e-06 - val_acc: 1.0000\n",
            "Epoch 58/100\n",
            "228/228 [==============================] - ETA: 0s - loss: 2.5444e-05 - acc: 1.0000\n",
            "Epoch 00058: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.5444e-05 - acc: 1.0000 - val_loss: 5.7295e-05 - val_acc: 1.0000\n",
            "Epoch 59/100\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 4.9120e-05 - acc: 1.0000\n",
            "Epoch 00059: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.7032e-05 - acc: 1.0000 - val_loss: 1.4102e-05 - val_acc: 1.0000\n",
            "Epoch 60/100\n",
            "212/228 [==========================>...] - ETA: 0s - loss: 6.3826e-06 - acc: 1.0000\n",
            "Epoch 00060: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.1846e-06 - acc: 1.0000 - val_loss: 5.8057e-06 - val_acc: 1.0000\n",
            "Epoch 61/100\n",
            "215/228 [===========================>..] - ETA: 0s - loss: 4.5965e-06 - acc: 1.0000\n",
            "Epoch 00061: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 5.0057e-06 - acc: 1.0000 - val_loss: 1.0312e-05 - val_acc: 1.0000\n",
            "Epoch 62/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 1.4486e-05 - acc: 1.0000\n",
            "Epoch 00062: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 1.4603e-05 - acc: 1.0000 - val_loss: 2.5192e-05 - val_acc: 1.0000\n",
            "Epoch 63/100\n",
            "227/228 [============================>.] - ETA: 0s - loss: 1.1192e-04 - acc: 0.9996\n",
            "Epoch 00063: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.1189e-04 - acc: 0.9996 - val_loss: 8.7631e-05 - val_acc: 1.0000\n",
            "Epoch 64/100\n",
            "227/228 [============================>.] - ETA: 0s - loss: 1.3944e-05 - acc: 1.0000\n",
            "Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.3937e-05 - acc: 1.0000 - val_loss: 5.3548e-07 - val_acc: 1.0000\n",
            "Epoch 65/100\n",
            "227/228 [============================>.] - ETA: 0s - loss: 3.1551e-07 - acc: 1.0000\n",
            "Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to /content/denrypt_1.2.h5\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.1535e-07 - acc: 1.0000 - val_loss: 4.8172e-08 - val_acc: 1.0000\n",
            "Epoch 66/100\n",
            "221/228 [============================>.] - ETA: 0s - loss: 1.9965e-07 - acc: 1.0000\n",
            "Epoch 00066: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.1284e-07 - acc: 1.0000 - val_loss: 6.1719e-07 - val_acc: 1.0000\n",
            "Epoch 67/100\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 1.6285e-05 - acc: 1.0000\n",
            "Epoch 00067: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.8033e-05 - acc: 1.0000 - val_loss: 4.5074e-05 - val_acc: 1.0000\n",
            "Epoch 68/100\n",
            "223/228 [============================>.] - ETA: 0s - loss: 3.4113e-05 - acc: 1.0000\n",
            "Epoch 00068: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.3858e-05 - acc: 1.0000 - val_loss: 1.9971e-05 - val_acc: 1.0000\n",
            "Epoch 69/100\n",
            "215/228 [===========================>..] - ETA: 0s - loss: 1.1376e-05 - acc: 1.0000\n",
            "Epoch 00069: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.1118e-05 - acc: 1.0000 - val_loss: 6.9221e-06 - val_acc: 1.0000\n",
            "Epoch 70/100\n",
            "228/228 [==============================] - ETA: 0s - loss: 3.5438e-06 - acc: 1.0000\n",
            "Epoch 00070: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.5438e-06 - acc: 1.0000 - val_loss: 3.3005e-06 - val_acc: 1.0000\n",
            "Epoch 71/100\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 4.1196e-06 - acc: 1.0000\n",
            "Epoch 00071: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 4.3647e-06 - acc: 1.0000 - val_loss: 1.2402e-05 - val_acc: 1.0000\n",
            "Epoch 72/100\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 1.0105e-04 - acc: 0.9994\n",
            "Epoch 00072: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 9.8382e-05 - acc: 0.9994 - val_loss: 4.2986e-05 - val_acc: 1.0000\n",
            "Epoch 73/100\n",
            "226/228 [============================>.] - ETA: 0s - loss: 1.3720e-05 - acc: 1.0000\n",
            "Epoch 00073: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.3655e-05 - acc: 1.0000 - val_loss: 4.9188e-07 - val_acc: 1.0000\n",
            "Epoch 74/100\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 6.8611e-07 - acc: 1.0000\n",
            "Epoch 00074: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.9180e-07 - acc: 1.0000 - val_loss: 8.3541e-07 - val_acc: 1.0000\n",
            "Epoch 75/100\n",
            "222/228 [============================>.] - ETA: 0s - loss: 2.9302e-06 - acc: 1.0000\n",
            "Epoch 00075: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.1783e-06 - acc: 1.0000 - val_loss: 1.3989e-05 - val_acc: 1.0000\n",
            "Epoch 76/100\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 1.4095e-05 - acc: 1.0000\n",
            "Epoch 00076: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.3806e-05 - acc: 1.0000 - val_loss: 8.2436e-06 - val_acc: 1.0000\n",
            "Epoch 77/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 1.4887e-05 - acc: 1.0000\n",
            "Epoch 00077: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.4866e-05 - acc: 1.0000 - val_loss: 2.0419e-05 - val_acc: 1.0000\n",
            "Epoch 78/100\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 4.6191e-05 - acc: 1.0000\n",
            "Epoch 00078: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.5276e-05 - acc: 1.0000 - val_loss: 1.6704e-05 - val_acc: 1.0000\n",
            "Epoch 79/100\n",
            "217/228 [===========================>..] - ETA: 0s - loss: 5.1213e-06 - acc: 1.0000\n",
            "Epoch 00079: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.9701e-06 - acc: 1.0000 - val_loss: 2.2141e-06 - val_acc: 1.0000\n",
            "Epoch 80/100\n",
            "228/228 [==============================] - ETA: 0s - loss: 1.0084e-05 - acc: 1.0000\n",
            "Epoch 00080: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 1.0084e-05 - acc: 1.0000 - val_loss: 1.1038e-05 - val_acc: 1.0000\n",
            "Epoch 81/100\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 3.4927e-05 - acc: 1.0000\n",
            "Epoch 00081: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.3790e-05 - acc: 1.0000 - val_loss: 3.6051e-06 - val_acc: 1.0000\n",
            "Epoch 82/100\n",
            "212/228 [==========================>...] - ETA: 0s - loss: 1.8335e-06 - acc: 1.0000\n",
            "Epoch 00082: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.8525e-06 - acc: 1.0000 - val_loss: 2.6214e-06 - val_acc: 1.0000\n",
            "Epoch 83/100\n",
            "214/228 [===========================>..] - ETA: 0s - loss: 6.8612e-06 - acc: 1.0000\n",
            "Epoch 00083: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.0234e-06 - acc: 1.0000 - val_loss: 2.1877e-05 - val_acc: 1.0000\n",
            "Epoch 84/100\n",
            "211/228 [==========================>...] - ETA: 0s - loss: 1.9671e-05 - acc: 1.0000\n",
            "Epoch 00084: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.0600e-05 - acc: 1.0000 - val_loss: 3.6940e-05 - val_acc: 1.0000\n",
            "Epoch 85/100\n",
            "218/228 [===========================>..] - ETA: 0s - loss: 2.6889e-05 - acc: 1.0000\n",
            "Epoch 00085: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.6355e-05 - acc: 1.0000 - val_loss: 2.0636e-05 - val_acc: 1.0000\n",
            "Epoch 86/100\n",
            "215/228 [===========================>..] - ETA: 0s - loss: 6.0304e-05 - acc: 1.0000\n",
            "Epoch 00086: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 5.7325e-05 - acc: 1.0000 - val_loss: 5.4924e-06 - val_acc: 1.0000\n",
            "Epoch 87/100\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 2.6662e-06 - acc: 1.0000\n",
            "Epoch 00087: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.5381e-06 - acc: 1.0000 - val_loss: 5.1358e-07 - val_acc: 1.0000\n",
            "Epoch 88/100\n",
            "223/228 [============================>.] - ETA: 0s - loss: 1.9934e-07 - acc: 1.0000\n",
            "Epoch 00088: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.9760e-07 - acc: 1.0000 - val_loss: 2.5721e-07 - val_acc: 1.0000\n",
            "Epoch 89/100\n",
            "215/228 [===========================>..] - ETA: 0s - loss: 1.6353e-06 - acc: 1.0000\n",
            "Epoch 00089: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7893e-06 - acc: 1.0000 - val_loss: 7.0618e-06 - val_acc: 1.0000\n",
            "Epoch 90/100\n",
            "224/228 [============================>.] - ETA: 0s - loss: 4.5049e-05 - acc: 1.0000\n",
            "Epoch 00090: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.4943e-05 - acc: 1.0000 - val_loss: 3.8393e-05 - val_acc: 1.0000\n",
            "Epoch 91/100\n",
            "220/228 [===========================>..] - ETA: 0s - loss: 1.1075e-05 - acc: 1.0000\n",
            "Epoch 00091: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0880e-05 - acc: 1.0000 - val_loss: 9.8976e-06 - val_acc: 1.0000\n",
            "Epoch 92/100\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 9.3958e-06 - acc: 1.0000\n",
            "Epoch 00092: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.2861e-06 - acc: 1.0000 - val_loss: 6.3425e-06 - val_acc: 1.0000\n",
            "Epoch 93/100\n",
            "223/228 [============================>.] - ETA: 0s - loss: 1.5949e-05 - acc: 1.0000\n",
            "Epoch 00093: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.5819e-05 - acc: 1.0000 - val_loss: 1.5261e-05 - val_acc: 1.0000\n",
            "Epoch 94/100\n",
            "223/228 [============================>.] - ETA: 0s - loss: 8.5153e-06 - acc: 1.0000\n",
            "Epoch 00094: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.7986e-06 - acc: 1.0000 - val_loss: 1.9959e-05 - val_acc: 1.0000\n",
            "Epoch 95/100\n",
            "225/228 [============================>.] - ETA: 0s - loss: 3.2344e-05 - acc: 1.0000\n",
            "Epoch 00095: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.2271e-05 - acc: 1.0000 - val_loss: 2.1226e-05 - val_acc: 1.0000\n",
            "Epoch 96/100\n",
            "215/228 [===========================>..] - ETA: 0s - loss: 5.5353e-06 - acc: 1.0000\n",
            "Epoch 00096: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.4335e-06 - acc: 1.0000 - val_loss: 7.5442e-06 - val_acc: 1.0000\n",
            "Epoch 97/100\n",
            "227/228 [============================>.] - ETA: 0s - loss: 6.1059e-06 - acc: 1.0000\n",
            "Epoch 00097: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.1032e-06 - acc: 1.0000 - val_loss: 3.8840e-06 - val_acc: 1.0000\n",
            "Epoch 98/100\n",
            "222/228 [============================>.] - ETA: 0s - loss: 6.6574e-06 - acc: 1.0000\n",
            "Epoch 00098: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.6396e-06 - acc: 1.0000 - val_loss: 8.3778e-06 - val_acc: 1.0000\n",
            "Epoch 99/100\n",
            "213/228 [===========================>..] - ETA: 0s - loss: 4.6325e-05 - acc: 1.0000\n",
            "Epoch 00099: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.0116e-05 - acc: 1.0000 - val_loss: 1.0066e-04 - val_acc: 1.0000\n",
            "Epoch 100/100\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 4.9663e-05 - acc: 1.0000\n",
            "Epoch 00100: val_loss did not improve from 0.00000\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.7404e-05 - acc: 1.0000 - val_loss: 3.0444e-06 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF6YSSSHYmtx"
      },
      "source": [
        "decrypted_text = decrypter.predict(decrypter_X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yVF08xCbtFJ"
      },
      "source": [
        "decrypted_int_text = change_output(decrypted_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZQgOIfDY6pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ce99bb-b9d2-4a10-9859-a0896323cd28"
      },
      "source": [
        "print(decrypted_text[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12YIpy4zhQds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1375bb06-5d87-4d45-ee7e-aef720d6d04a"
      },
      "source": [
        "print(decrypted_int_text[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TagmGzNgf-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47946ca0-87c4-4062-883e-f137ae2c245a"
      },
      "source": [
        "print(decrypter_Y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBGt8kz9cm-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f96063-efa9-4a6f-d0c6-b51b45c16ce8"
      },
      "source": [
        "\n",
        "print(np.argmax(decrypted_text[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOv3Lse_cqTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfe2836-e519-4be4-a791-6869822b3cdf"
      },
      "source": [
        "print(np.argmax(decrypter_Y_train[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUeBDUDqgxWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ae1f4a-e406-4fbd-b93c-de882e08d932"
      },
      "source": [
        "print(decrypted_text[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUtnWwnohYRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2de0143-d64b-4ff7-8bba-3cb36cd7a89b"
      },
      "source": [
        "print(decrypted_int_text[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFO2H-Efgtd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43510a65-d81b-46db-c7b4-47d0bf9b5e1a"
      },
      "source": [
        "print(decrypter_Y_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DustfvvNZifM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8481354-2b74-46aa-d3b3-a419c301b42f"
      },
      "source": [
        "print(np.argmax(decrypted_text[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XlIEAunaqp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2028d8fa-1366-44d9-b29e-7467813957f7"
      },
      "source": [
        "print(np.argmax(decrypter_Y_train[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hmG6OSvhMQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19768061-d4af-4dc4-b5b4-a20c2eccd3b1"
      },
      "source": [
        "accuracy(decrypted_int_text, decrypter_Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr20f-ilhj2x"
      },
      "source": [
        "decrypted_Y_test_pred = decrypter.predict(decrypter_X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jV1SYTaBH4-"
      },
      "source": [
        "decrypted_Y_test_pred = change_output(decrypted_Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-1V_q7CA_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17468283-9b06-4d96-d2d1-00c382cf27f4"
      },
      "source": [
        "accuracy(decrypted_Y_test_pred, decrypter_Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for the given batch is : 100.0  % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEwrOfRJdTQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20fcf9d3-b8b8-46cd-b3bf-50ca5957d9dd"
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = decrypter.to_json()\n",
        "with open(\"decrypter_v1_2_3.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "decrypter.save_weights(\"decrypter_v1_2_3.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlNDUCOPx2ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb84a44e-97a3-4792-b4e4-93c3d025f864"
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('/content/decrypter_v1_2_3.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/decrypter_v1_2_3.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ZcCpYY8h9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3ce8ff-76c9-4715-ce9e-e073c87c22f7"
      },
      "source": [
        "print(\"Decrypter can be loaded and run\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decrypter can be loaded and run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hfpoM1zA9dR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}